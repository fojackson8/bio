{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "\n",
    "1. load and concatenate data\n",
    "2. feature selection (Feature encoding if necessary)\n",
    "3. benchmark ML\n",
    "4. optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "files = os.listdir()\n",
    "\n",
    "\n",
    "## Get all protein names \n",
    "protein_names = [u.split('_')[0] for u in files if 'actives_rdkit_features.csv' in u]\n",
    "\n",
    "aa2ar_actives = pd.read_csv('aa2ar_actives_rdkit_features.csv')\n",
    "aa2ar_decoys = pd.read_csv('aa2ar_decoys_rdkit_features.csv')\n",
    "\n",
    "all_proteins = {}\n",
    "for protein in protein_names:\n",
    "    for file in files:\n",
    "        if protein in file:\n",
    "            tmp1 = pd.read_csv(protein+ '_actives_rdkit_features.csv')\n",
    "            tmp1['ACTIVE'] = 1\n",
    "            tmp2 = pd.read_csv(protein+'_decoys_rdkit_features.csv')\n",
    "            tmp2 = tmp2.sample(n=500)\n",
    "            tmp2['ACTIVE'] = 0\n",
    "            frames = [tmp1,tmp2]\n",
    "            all_proteins[protein] = pd.concat(frames).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic regression to test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7397685950413222"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Basic sklearn model building pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# get the protein of interest from the dict\n",
    "df = all_proteins['aa2ar']\n",
    "\n",
    "\n",
    "\n",
    "# define X and y \n",
    "X = df.drop(['Unnamed: 0','ACTIVE'],axis=1)\n",
    "y = all_proteins['aa2ar']['ACTIVE']\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=0)\n",
    "\n",
    "\n",
    "#clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(x_train, y_train)\n",
    "# pred = clf.predict(x_test)\n",
    "# clf.score(X, y)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, max_depth=2,random_state=2)\n",
    "rf.fit(x_train, y_train)\n",
    "rf_pred = rf.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "\n",
    "#confusion_matrix(y_test,rf_pred)\n",
    "r2_score(y_test,rf_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method score in module sklearn.base:\n",
      "\n",
      "score(X, y, sample_weight=None) method of sklearn.ensemble.forest.RandomForestClassifier instance\n",
      "    Returns the mean accuracy on the given test data and labels.\n",
      "    \n",
      "    In multi-label classification, this is the subset accuracy\n",
      "    which is a harsh metric since you require for each sample that\n",
      "    each label set be correctly predicted.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like, shape = (n_samples, n_features)\n",
      "        Test samples.\n",
      "    \n",
      "    y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      "        True labels for X.\n",
      "    \n",
      "    sample_weight : array-like, shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    score : float\n",
      "        Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics\n",
    "\n",
    "- Look at the number of compounds that are active for multiple proteins, and the number of compounds that are inactive against multiple compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
